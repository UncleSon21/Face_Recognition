{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:31.911628Z",
     "start_time": "2024-10-08T03:27:28.923922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ],
   "id": "de3df47e27f77a1b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:31.933184Z",
     "start_time": "2024-10-08T03:27:31.913133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_folder = 'archive/lfw-deepfunneled/lfw-deepfunneled'\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "labels = []\n",
    "\n",
    "# Create haar cascade model\n",
    "haar_cascade = cv2.CascadeClassifier('haar_face.xml')"
   ],
   "id": "d72aec42f3cf656e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:32.628391Z",
     "start_time": "2024-10-08T03:27:31.933184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name = []\n",
    "def count_single_image(img_folder):\n",
    "    count = 0\n",
    "    \n",
    "    # Loop through each folder in the img_folder\n",
    "    for subdir in os.listdir(img_folder):\n",
    "        subdir_path = os.path.join(img_folder, subdir)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(subdir_path):\n",
    "            # Count how many image files are in the folder\n",
    "            image_files = [f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))]\n",
    "            \n",
    "            # Check if there's exactly one image file\n",
    "            if len(image_files) == 1:\n",
    "                count += 1\n",
    "                name.append(subdir)\n",
    "    \n",
    "    return count\n",
    "    # Call the function and print the result\n",
    "count = count_single_image(img_folder)\n",
    "print(f\"Number of folders with exactly one image: {count}\")\n",
    "for name in name[:10]:\n",
    "    print(f\"Name of the first 10 folders with single image: {name}\")"
   ],
   "id": "63c5a2957be48c5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folders with exactly one image: 4069\n",
      "Name of the first 10 folders with single image: Aaron_Eckhart\n",
      "Name of the first 10 folders with single image: Aaron_Guiel\n",
      "Name of the first 10 folders with single image: Aaron_Patterson\n",
      "Name of the first 10 folders with single image: Aaron_Pena\n",
      "Name of the first 10 folders with single image: Aaron_Tippin\n",
      "Name of the first 10 folders with single image: Abbas_Kiarostami\n",
      "Name of the first 10 folders with single image: Abba_Eban\n",
      "Name of the first 10 folders with single image: Abdel_Aziz_Al-Hakim\n",
      "Name of the first 10 folders with single image: Abdel_Madi_Shabneh\n",
      "Name of the first 10 folders with single image: Abdulaziz_Kamilov\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:32.632643Z",
     "start_time": "2024-10-08T03:27:32.629623Z"
    }
   },
   "source": [
    "def restrained_cpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:32.643624Z",
     "start_time": "2024-10-08T03:27:32.634163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def createLabels():\n",
    "    for subdir in os.listdir(img_folder):\n",
    "        subdir_path = os.path.join(img_folder, subdir)\n",
    "\n",
    "        # Only process directories\n",
    "        if os.path.isdir(subdir_path):\n",
    "            image_files = [f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))]\n",
    "            \n",
    "            # Check if there's exactly one image file\n",
    "            if len(image_files) > 1:\n",
    "                labels.append(subdir)"
   ],
   "id": "9e01f5cd3734dfb1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:32.648864Z",
     "start_time": "2024-10-08T03:27:32.644632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def importImages_Labels():\n",
    "    for label in labels:\n",
    "        path = os.path.join(img_folder, label)\n",
    "        # Loop through each image in the sub-folder\n",
    "        for image_name in os.listdir(path):\n",
    "            image_path = os.path.join(path, image_name)\n",
    "\n",
    "            # Load the image using OpenCV\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is not None:\n",
    "                # # Convert image to grayscale\n",
    "                # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                #\n",
    "                # # detect face in the image (increase image size 10% and minimal neighbors = 3)\n",
    "                # faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3)\n",
    "                #\n",
    "                # for (x, y, w, h) in faces_rect:\n",
    "                #     faces_roi = gray[y:y + h, x:x + w]\n",
    "                #     X.append(faces_roi)\n",
    "                #     Y.append(labels.index(label))\n",
    "                \n",
    "                # Resize all images to the same size (200x200 pxl)\n",
    "                # image = cv2.resize(image, (200, 200))\n",
    "                \n",
    "                X.append(image)\n",
    "                Y.append(labels.index(label))\n",
    "\n",
    "            else:\n",
    "                print(f\"Warning: Could not load image {image_path}\")\n",
    "\n",
    "    print(\"Importing images and labels completed!\")"
   ],
   "id": "32b3ddb3dc8652ea",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:32.652489Z",
     "start_time": "2024-10-08T03:27:32.648864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model_Eigenfaces(X_train, Y_train):\n",
    "    model = cv2.face.EigenFaceRecognizer_create()\n",
    "    model.train(X_train, Y_train)\n",
    "    print(\"Model training completed!\")\n",
    "    return model"
   ],
   "id": "b4c031b971e2f9ca",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:32.656574Z",
     "start_time": "2024-10-08T03:27:32.652489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(X_train, Y_train):\n",
    "    model = cv2.face.LBPHFaceRecognizer_create()\n",
    "    model.train(X_train, Y_train)\n",
    "    print(\"Model training completed!\")\n",
    "    return model"
   ],
   "id": "7e4bcf8c9fa6c308",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:32.661779Z",
     "start_time": "2024-10-08T03:27:32.656574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, X_test, Y_test):\n",
    "    # Initialize lists to hold the results\n",
    "    predictions = []\n",
    "    correct_labels = []\n",
    "    loop = len(X_test)\n",
    "    count = 0\n",
    "    # Loop through each of the first 500 images\n",
    "    for i in range(loop):\n",
    "        test_image = X_test[i]\n",
    "        \n",
    "        gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces_rect = haar_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "        \n",
    "        for (x, y, w, h) in faces_rect:\n",
    "            faces_roi = gray[y:y + h, x:x + w]\n",
    "            label, confidence = model.predict(faces_roi)\n",
    "        \n",
    "        if labels[label] == labels[Y_test[i]]:\n",
    "            count += 1\n",
    "            \n",
    "        # Print the prediction and actual label\n",
    "        correct_percent = count / loop * 100\n",
    "        print(f'{i} / {loop} ({correct_percent}) Predicted Label: {labels[label]}, Confidence: {confidence}, Actual Label: {labels[Y_test[i]]}')\n",
    "\n",
    "        # Check if the prediction is correct\n",
    "        # if labels[label] == labels[Y_test[i]]:\n",
    "        #     img = X_test[i]  # The original image in color or grayscale\n",
    "        # \n",
    "        #     # Annotate the image with the predicted label\n",
    "        #     cv2.putText(gray, str(labels[label]), (20, 20), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), thickness=2)\n",
    "        #     cv2.rectangle(gray, (0, 0), (250, 250), (0, 255, 0), 2)\n",
    "        #     cv2.imshow('Detected Face', gray)\n",
    "        # \n",
    "        #     cv2.waitKey(0)\n",
    "        #     cv2.destroyAllWindows()\n",
    "\n",
    "        # Append the predicted label and the true label to the lists\n",
    "        predictions.append(label)\n",
    "        correct_labels.append(Y_test[i])\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct_predictions = sum([1 for p, c in zip(predictions, correct_labels) if p == c])\n",
    "    \n",
    "    return predictions, correct_labels\n",
    "    "
   ],
   "id": "5d08cdcef8ae712e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:32.666530Z",
     "start_time": "2024-10-08T03:27:32.662795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def real_time_face_recognition(model):\n",
    "    # Open webcam for capturing video\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Convert to grayscale (required for face detection)\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame using the Haar Cascade\n",
    "        faces_rect = haar_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=4)\n",
    "\n",
    "        # Loop through all the detected faces\n",
    "        for (x, y, w, h) in faces_rect:\n",
    "            faces_roi = gray_frame[y:y + h, x:x + w]  # Extract the region of interest (the face)\n",
    "\n",
    "            # Predict the label of the face\n",
    "            label, confidence = model.predict(faces_roi)\n",
    "\n",
    "            # Display the predicted label and confidence on the frame\n",
    "            cv2.putText(frame, f'{labels[label]} - {confidence:.2f}', (x, y - 10), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame with face detection and recognition\n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "        # Press 'q' to exit the webcam feed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything is done, release the capture and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "cc543cef8ccda531",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:32.670512Z",
     "start_time": "2024-10-08T03:27:32.667538Z"
    }
   },
   "cell_type": "code",
   "source": "restrained_cpu()",
   "id": "d7ea5ae93412522c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:40.569068Z",
     "start_time": "2024-10-08T03:27:32.671518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "createLabels()\n",
    "importImages_Labels()"
   ],
   "id": "c86b4caa9bc1fe24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing images and labels completed!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T03:27:40.576124Z",
     "start_time": "2024-10-08T03:27:40.570285Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)",
   "id": "b2f2b9b49b29a1a0",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-08T03:27:40.579151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_gray_rect = []\n",
    "Y_train_gray_rect = []\n",
    "X_train_gray = []\n",
    "Y_train_gray = []\n",
    "\n",
    "for idx, img in enumerate(X_train):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    X_train_gray.append(gray)\n",
    "    Y_train_gray.append(Y_train[idx])\n",
    "    \n",
    "    faces_rect = haar_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "    for (x, y, w, h) in faces_rect:\n",
    "        faces_roi = gray[y:y + h, x:x + w]\n",
    "        X_train_gray_rect.append(faces_roi)\n",
    "        Y_train_gray_rect.append(Y_train[idx])\n",
    "        "
   ],
   "id": "abdad60a7413855b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_gray_np = np.array(X_train_gray)\n",
    "Y_train_gray_np = np.array(Y_train_gray)"
   ],
   "id": "3cd89edbf81efcdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_np = np.array(X_train_gray_rect, dtype='object')\n",
    "Y_train_np = np.array(Y_train_gray_rect)\n",
    "\n",
    "# trained_model_LBH = train_model(X_train_np, Y_train_np)"
   ],
   "id": "a7f709884d5224dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "trained_model_eigenfaces = train_model_Eigenfaces(X_train_gray_np, Y_train_gray_np)",
   "id": "30dabf087056ca1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "# real_time_face_recognition(trained_model)",
   "id": "408a1b9421d36dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "# predictions, correct_labels = test_model(trained_model_eigenfaces, X_test, Y_test)",
   "id": "e8b2b2c3c850e423",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# accuracy = accuracy_score(predictions, correct_labels)\n",
    "# precision = precision_score(predictions, correct_labels)\n",
    "# recall = recall_score(predictions, correct_labels)\n",
    "# \n",
    "# # Print results\n",
    "# print(f\"Total test images: {len(correct_labels)}\")\n",
    "# print(f\"Correct predictions: {correct_labels}\")\n",
    "# print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1 Score: {f1_score(predictions, correct_labels)}\")"
   ],
   "id": "b34382f911df8a10",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
