{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T01:13:59.730669Z",
     "start_time": "2024-10-08T01:13:59.251806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ],
   "id": "de3df47e27f77a1b",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _multiarray_umath: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing _multiarray_umath: The specified module could not be found."
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "_multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;31mImportError\u001B[0m: _multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy._core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\__init__.py:47\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf2 \u001B[38;5;28;01mas\u001B[39;00m _tf2\n\u001B[0;32m     45\u001B[0m _tf2\u001B[38;5;241m.\u001B[39menable()\n\u001B[1;32m---> 47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __internal__\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __operators__\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m audio\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autograph\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m decorator\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dispatch\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mag_ctx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m control_status_ctx \u001B[38;5;66;03m# line: 34\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimpl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf_convert\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01minspect\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mthreading\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ag_logging\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtf_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf_export\n\u001B[0;32m     25\u001B[0m stacks \u001B[38;5;241m=\u001B[39m threading\u001B[38;5;241m.\u001B[39mlocal()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontext_managers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m control_dependency_on_returns\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmisc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m alias_tensors\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtensor_list\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dynamic_list_append\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcontextlib\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_array_ops\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcontrol_dependency_on_returns\u001B[39m(return_value):\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:50\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf2\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tf_session\n\u001B[1;32m---> 50\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m core\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m monitoring\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:37\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tf_session\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cancellation\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m execute\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m executor\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m monitoring\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:21\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tfe\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m core\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dtypes\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_conversion_registry\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_shape\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:21\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdataclasses\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Type, Sequence, Optional\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mml_dtypes\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m types_pb2\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\ml_dtypes\\__init__.py:32\u001B[0m\n\u001B[0;32m     16\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__version__\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbfloat16\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint4\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     28\u001B[0m ]\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Type\n\u001B[1;32m---> 32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mml_dtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_finfo\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m finfo\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mml_dtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_iinfo\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m iinfo\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mml_dtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_ml_dtypes_ext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m bfloat16\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\ml_dtypes\\_finfo.py:19\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Overload of numpy.finfo to handle dtypes defined in ml_dtypes.\"\"\"\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dict\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mml_dtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_ml_dtypes_ext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m bfloat16\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mml_dtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_ml_dtypes_ext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m float8_e4m3b11fnuz\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mml_dtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_ml_dtypes_ext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m float8_e4m3fn\n",
      "\u001B[1;31mImportError\u001B[0m: numpy._core.umath failed to import"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:46:27.980434Z",
     "start_time": "2024-09-27T14:46:27.952130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_folder = 'archive/lfw-deepfunneled/lfw-deepfunneled'\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "labels = []\n",
    "\n",
    "# Create haar cascade model\n",
    "haar_cascade = cv2.CascadeClassifier('haar_face.xml')"
   ],
   "id": "d72aec42f3cf656e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:46:28.936919Z",
     "start_time": "2024-09-27T14:46:27.981571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name = []\n",
    "def count_single_image(img_folder):\n",
    "    count = 0\n",
    "    \n",
    "    # Loop through each folder in the img_folder\n",
    "    for subdir in os.listdir(img_folder):\n",
    "        subdir_path = os.path.join(img_folder, subdir)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(subdir_path):\n",
    "            # Count how many image files are in the folder\n",
    "            image_files = [f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))]\n",
    "            \n",
    "            # Check if there's exactly one image file\n",
    "            if len(image_files) == 1:\n",
    "                count += 1\n",
    "                name.append(subdir)\n",
    "    \n",
    "    return count\n",
    "    # Call the function and print the result\n",
    "count = count_single_image(img_folder)\n",
    "print(f\"Number of folders with exactly one image: {count}\")\n",
    "for name in name[:10]:\n",
    "    print(f\"Name of the first 10 folders with single image: {name}\")"
   ],
   "id": "63c5a2957be48c5c",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-27T14:46:28.941043Z",
     "start_time": "2024-09-27T14:46:28.938344Z"
    }
   },
   "source": [
    "def restrained_cpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:46:28.954376Z",
     "start_time": "2024-09-27T14:46:28.942136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def createLabels():\n",
    "    for subdir in os.listdir(img_folder):\n",
    "        subdir_path = os.path.join(img_folder, subdir)\n",
    "\n",
    "        # Only process directories\n",
    "        if os.path.isdir(subdir_path):\n",
    "            image_files = [f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))]\n",
    "            \n",
    "            # Check if there's exactly one image file\n",
    "            if len(image_files) > 1:\n",
    "                labels.append(subdir)"
   ],
   "id": "9e01f5cd3734dfb1",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:46:28.958984Z",
     "start_time": "2024-09-27T14:46:28.955443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def importImages_Labels():\n",
    "    for label in labels:\n",
    "        path = os.path.join(img_folder, label)\n",
    "        # Loop through each image in the sub-folder\n",
    "        for image_name in os.listdir(path):\n",
    "            image_path = os.path.join(path, image_name)\n",
    "\n",
    "            # Load the image using OpenCV\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is not None:\n",
    "                # # Convert image to grayscale\n",
    "                # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                #\n",
    "                # # detect face in the image (increase image size 10% and minimal neighbors = 3)\n",
    "                # faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3)\n",
    "                #\n",
    "                # for (x, y, w, h) in faces_rect:\n",
    "                #     faces_roi = gray[y:y + h, x:x + w]\n",
    "                #     X.append(faces_roi)\n",
    "                #     Y.append(labels.index(label))\n",
    "                X.append(image)\n",
    "                Y.append(labels.index(label))\n",
    "\n",
    "            else:\n",
    "                print(f\"Warning: Could not load image {image_path}\")\n",
    "\n",
    "    print(\"Importing images and labels completed!\")"
   ],
   "id": "32b3ddb3dc8652ea",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:46:28.963394Z",
     "start_time": "2024-09-27T14:46:28.958984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(X_train, Y_train):\n",
    "    model = cv2.face.LBPHFaceRecognizer_create()\n",
    "    model.train(X_train, Y_train)\n",
    "    print(\"Model training completed!\")\n",
    "    return model"
   ],
   "id": "7e4bcf8c9fa6c308",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:46:28.970698Z",
     "start_time": "2024-09-27T14:46:28.964601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, X_test, Y_test):\n",
    "    # Initialize lists to hold the results\n",
    "    predictions = []\n",
    "    correct_labels = []\n",
    "    loop = len(X_test)\n",
    "    count = 0\n",
    "    # Loop through each of the first 500 images\n",
    "    for i in range(loop):\n",
    "        test_image = X_test[i]\n",
    "        \n",
    "        gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces_rect = haar_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "        \n",
    "        for (x, y, w, h) in faces_rect:\n",
    "            faces_roi = gray[y:y + h, x:x + w]\n",
    "            label, confidence = model.predict(faces_roi)\n",
    "        \n",
    "        if labels[label] == labels[Y_test[i]]:\n",
    "            count += 1\n",
    "            \n",
    "        # Print the prediction and actual label\n",
    "        correct_percent = count / loop * 100\n",
    "        print(f'{i} / {loop} ({correct_percent}) Predicted Label: {labels[label]}, Confidence: {confidence}, Actual Label: {labels[Y_test[i]]}')\n",
    "\n",
    "        # Check if the prediction is correct\n",
    "        # if labels[label] == labels[Y_test[i]]:\n",
    "        #     img = X_test[i]  # The original image in color or grayscale\n",
    "        # \n",
    "        #     # Annotate the image with the predicted label\n",
    "        #     cv2.putText(gray, str(labels[label]), (20, 20), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), thickness=2)\n",
    "        #     cv2.rectangle(gray, (0, 0), (250, 250), (0, 255, 0), 2)\n",
    "        #     cv2.imshow('Detected Face', gray)\n",
    "        # \n",
    "        #     cv2.waitKey(0)\n",
    "        #     cv2.destroyAllWindows()\n",
    "\n",
    "        # Append the predicted label and the true label to the lists\n",
    "        predictions.append(label)\n",
    "        correct_labels.append(Y_test[i])\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    correct_predictions = sum([1 for p, c in zip(predictions, correct_labels) if p == c])\n",
    "\n",
    "    accuracy = correct_predictions / len(correct_labels) * 100\n",
    "    precision = precision_score(correct_labels, predictions, average='macro')\n",
    "    recall = recall_score(correct_labels, predictions, average='macro')\n",
    "    f1 = f1_score(correct_labels, predictions, average='macro')\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Total test images: {len(correct_labels)}\")\n",
    "    print(f\"Correct predictions: {correct_predictions}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}%\")\n",
    "    print(f\"Recall: {recall:.2f}%\")\n",
    "    print(f\"F1 Score: {f1:.2f}%\")"
   ],
   "id": "5d08cdcef8ae712e",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T01:25:22.154362Z",
     "start_time": "2024-10-08T01:25:22.149226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def real_time_face_recognition(model):\n",
    "    # Open webcam for capturing video\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Convert to grayscale (required for face detection)\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame using the Haar Cascade\n",
    "        faces_rect = haar_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=4)\n",
    "\n",
    "        # Loop through all the detected faces\n",
    "        for (x, y, w, h) in faces_rect:\n",
    "            faces_roi = gray_frame[y:y + h, x:x + w]  # Extract the region of interest (the face)\n",
    "\n",
    "            # Predict the label of the face\n",
    "            label, confidence = model.predict(faces_roi)\n",
    "\n",
    "            # Display the predicted label and confidence on the frame\n",
    "            cv2.putText(frame, f'{labels[label]} - {confidence:.2f}', (x, y - 10), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame with face detection and recognition\n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "        # Press 'q' to exit the webcam feed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything is done, release the capture and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "c99341c05cfffcca",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T01:34:31.407896Z",
     "start_time": "2024-10-08T01:34:31.402720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def real_time_face_recognition(model):\n",
    "    # Open webcam for capturing video\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Convert to grayscale (required for face detection)\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame using the Haar Cascade\n",
    "        faces_rect = haar_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=4)\n",
    "\n",
    "        # Loop through all the detected faces\n",
    "        for (x, y, w, h) in faces_rect:\n",
    "            faces_roi = gray_frame[y:y + h, x:x + w]  # Extract the region of interest (the face)\n",
    "\n",
    "            # Predict the label of the face\n",
    "            label, confidence = model.predict(faces_roi)\n",
    "\n",
    "            # Display the predicted label and confidence on the frame\n",
    "            cv2.putText(frame, f'{labels[label]} - {confidence:.2f}', (x, y - 10), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame with face detection and recognition\n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "        # Press 'q' to exit the webcam feed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything is done, release the capture and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "2dc6cc382e1c05ab",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:46:28.977030Z",
     "start_time": "2024-09-27T14:46:28.971880Z"
    }
   },
   "cell_type": "code",
   "source": "restrained_cpu()",
   "id": "d7ea5ae93412522c",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:46:41.394583Z",
     "start_time": "2024-09-27T14:46:28.978049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "createLabels()\n",
    "importImages_Labels()"
   ],
   "id": "c86b4caa9bc1fe24",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:46:41.402057Z",
     "start_time": "2024-09-27T14:46:41.394583Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)",
   "id": "b2f2b9b49b29a1a0",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:47:14.108829Z",
     "start_time": "2024-09-27T14:46:41.403066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_gray_rect = []\n",
    "Y_train_gray_rect = []\n",
    "\n",
    "for idx, img in enumerate(X_train):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces_rect = haar_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "    for (x, y, w, h) in faces_rect:\n",
    "        faces_roi = gray[y:y + h, x:x + w]\n",
    "        X_train_gray_rect.append(faces_roi)\n",
    "        Y_train_gray_rect.append(Y_train[idx])\n",
    "        "
   ],
   "id": "abdad60a7413855b",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:47:20.103279Z",
     "start_time": "2024-09-27T14:47:14.108829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_np = np.array(X_train_gray_rect, dtype='object')\n",
    "Y_train_np = np.array(Y_train_gray_rect)\n",
    "\n",
    "trained_model = train_model(X_train_np, Y_train_np)"
   ],
   "id": "a7f709884d5224dd",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "real_time_face_recognition(trained_model)",
   "id": "fb161e8a466567c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:58:22.240461Z",
     "start_time": "2024-09-27T14:47:20.103279Z"
    }
   },
   "cell_type": "code",
   "source": "# test_model(trained_model, X_test, Y_test)",
   "id": "e8b2b2c3c850e423",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T14:58:22.243292Z",
     "start_time": "2024-09-27T14:58:22.240461Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b34382f911df8a10",
   "execution_count": 14,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
